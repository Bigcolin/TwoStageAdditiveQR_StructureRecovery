module additiveQR
include("dataGen.ji")
using LinearAlgebra, Optim, Distributions
import Base.Threads.@spawn, Base.Threads.@threads
using BasicBSpline

function bisec_search(f, r, l, tol = 1e-4)
# this search is based on f has a global optimizer
    delta = l - r
    yi = 0
    while delta > tol
        b_ = LinRange(r, l, 3)
        y_ = f.(b_)
        ind = argmin(y_)
        yi = b_[ind]
        if ind == 1
            r = b_[1]
            l = b_[2]
        end
        
        if ind == 3
            r = b_[2]
            l = b_[3]
        end
        
        if ind == 2
            if y_[1] < y_[3]
                r = b_[1]
                l = b_[2]
            else
                r = b_[2]
                l = b_[3]
            end
        end
        delta = l - r
    end
    yi
end

struct bsplElems
    pBasis::Int
    nBasis::Int
    knot::Array{Float64, 1}
    function bsplElems(nBasis::Int, pBasis::Int)
        knot = LinRange(-2, 2, pBasis + nBasis + 1)
        new(pBasis, nBasis, knot)
    end

    function bsplElems(knot::Array{Float64, 1}, pBasis::Int)
        nBasis = length(knot) - pBasis - 1
        new(pBasis, nBasis, knot)
    end
end

# knots = [-2.0,-.5, -.25, 0, .25, .5, 2.0]
# pbs = 2
# nbs = 3  # n = 3, p = 2 is the best basis para. according to QBIC
# elems0 = bsplElems(pbs, nbs)

# ker(x, a = 3.5) = pdf(Truncated(Normal(0,1), -a, a), a*x)
ker(x) = pdf(Normal(0, 1), x)

function optimfunc(f, init_value, tols = 1e-3)
    res = optimize(f, init_value, method=BFGS(), f_tol=tols)
    return res
end

function assemblePx(X, p)
    n, d = size(X)
    Ak = []
    for k in 1:d
        ak = p.(X[:,k])
        ak = hcat(ak...)
        push!(Ak, ak')
    end
    A = hcat(Ak...)
    return A , Ak
end

struct twoStageAddQR
    basisElems::bsplElems
    pfuncs
    ρ
    Mx::Array{Float64, 2}
    coef::Array{Float64, 1}
    qbic::Float64
    trainData::data
    intercept::Float64
    y_min::Float64
    y_max::Float64
    function twoStageAddQR(splElems::bsplElems, trainData::data, alpha::Float64, u::Bool=false)
        ρ(x, α = alpha) = abs(x) + (2α - 1)x
        nBasis = splElems.nBasis
        pBasis = splElems.pBasis
        knots = Knots(splElems.knot)
        bsp = BSplineSpace(pBasis, knots)
        pfuncs(x) = bsplinebasis(bsp, x)
        n, d = size(trainData.X)
        A, Ak = assemblePx(trainData.X, pfuncs)
        if u
            Intercept = ones(n, 1)
            θ_0 = rand(d*nBasis + 1)
            A = hcat(Intercept, A)
            func(θ) = sum(ρ.(trainData.y - A*θ))./n
            res = optimfunc(func, θ_0)
            # QBIC: determined by basis parameters
            qbic = n*log(n*res.minimum) + 2log(n)*nBasis
            coef = res.minimizer[2:end]
            intercept = res.minimizer[1]
        else
            θ_0 = rand(d*nBasis)
            func_(θ) = sum(ρ.(trainData.y - A*θ))./n
            res = optimfunc(func_, θ_0)
            # QBIC: determined by basis parameters
            qbic = n*log(n*res.minimum) + 2log(n)*nBasis
            coef = res.minimizer   
            intercept = 0      
        end
        M = zeros(n, d)
        coefm = reshape(coef, nBasis, d)
        for k in 1:d
            M[:,k] = Ak[k] * coefm[:,k]
        end
        y_min = minimum(trainData.y) 
        y_max = maximum(trainData.y)
        new(splElems, pfuncs, ρ, M, coef, qbic, trainData, intercept, y_min, y_max)
    end

end

function predictor(model::twoStageAddQR, Xt::Array{Float64, 2})
    # println("Predicting via model on stage 1... \n")
    A, = assemblePx(Xt, model.pfuncs)
    A*model.coef .+ model.intercept
end

function predictor(model::twoStageAddQR, xi::Float64, λi::Float64, i::Int, ∇ = 2)
    # println("Predicting vector xn via model on stage 2... \n")
    X = model.trainData.X
    n,d = size(X)
    msum = sum(model.Mx, dims=2)
    u = model.intercept
    yi = 0
    h = 1/λi
    
    if ∇ == 2
        b0 = zeros(2)
        f_d2(b::Array{Float64, 1}) = sum(model.ρ.((model.trainData.y .- u .- b[1] .- b[2].*(X[:,i] .- xi)./h)
                                .- (msum .- model.Mx[:,i])) .* ker.((xi .- X[:,i])./h))./(n*h)
        res = optimfunc(f_d2, b0)
        yi = res.minimizer[1]
    
    elseif ∇ == 1
        f_d1(b) = sum(model.ρ.((model.trainData.y .- u .- b)
                                .- (msum .- model.Mx[:,i])) .* ker.((xi .- X[:,i])./h))./(n*h)
        r = model.y_min
        l = model.y_max
        yi = bisec_search(f_d1, r, l)

    elseif ∇ == 3
        b0 = zeros(3)    
        f_d3(b::Array{Float64, 1}) = sum(model.ρ.((model.trainData.y .- u .- b[1] .- b[2].*(X[:,i] .- xi)./h .- b[3].*((X[:,i] .- xi)./h).^2)
                                .- (msum .- model.Mx[:,i])) .* ker.((xi .- X[:,i])./h))./(n*h)
        res = optimfunc(f_d3, b0)
        yi = res.minimizer[1]
    end
    yi
end

####
# Parallel on d
function predictor(model::twoStageAddQR, Xi::Array{Float64, 1}, λi::Float64, i::Int, ∇)
    # println("Predicting vector xn via model on stage 2... \n")
    X = model.trainData.X
    n = length(Xi)
    yi = zeros(n)
    for k in 1:n
        xi = Xi[k]
        yi[k] = predictor(model, xi, λi, i, ∇)
    end
    yi
end

# Parallel on n
function predictor(model::twoStageAddQR, Xn::Array{Float64, 1}, λ::Array{Float64, 1}, ∇)
    # println("Predicting vector xn via model on stage 2... \n")
    # X = model.trainData.X
    d = length(Xn)
    yn = 0
    for k in 1:d
        xk = Xn[k]
        yn += predictor(model, xk, λ[k], k, ∇)
    end
    yn
end

function predictor(model::twoStageAddQR, Xt::Array{Float64, 2}, λ::Array{Float64, 1}, ∇ = 2) # 之前是对d并行，最多只有d个线程，这里改成对n并F行
    # println("Predicting matrix Xt via model on stage 2... \n")
    n, d = size(Xt)
    u = model.intercept
    y = ones(n).*u
    parallel = 0
    if parallel == 'n'
        @threads for i in 1:n
            y[i] = predictor(model, Xt[i, :], λ, ∇)
        end

    elseif parallel == 'd'
        @threads for i in 1:d
            yi = predictor(model, Xt[:, i], λ[i], i, ∇)
            y += yi
        end

    else
        for i in 1:n
            y[i] = predictor(model, Xt[i, :], λ, ∇)
        end
    end


    y
    
end




SAE(model::twoStageAddQR, λ::Array{Float64, 1}, ∇) = sum(model.ρ.(model.trainData.y - predictor(model, model.trainData.X, λ, ∇)))

SAE(model::twoStageAddQR, λ::Array{Float64, 1}, X::Array{Float64, 2}, y::Array{Float64, 1}, ∇) = sum(model.ρ.(y - predictor(model, X, λ, ∇)))

end # end module
# @Threads.threads 
# tasks = Vector{Task}(undef, d)

    # for i in 1:d
    #     tasks[i] = @spawn func(i)
    # end
    # for i in 1:d
    #     try tasks[i]
    #     catch e
    #         if isa(e, UndefRefError)
    #             continue
    #         else
    #             wait(task[i])
    #         end
    #     end
    # end
    # while count != d
    #     sleep(0.1)
    # end
    # wait(tasks[d])
